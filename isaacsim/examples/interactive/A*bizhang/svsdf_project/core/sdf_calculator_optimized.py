# core/sdf_calculator_optimized.py
"""
ç­¾åè·ç¦»åœº(SDF)è®¡ç®—å™¨ - å·¥ä¸šçº§ä¼˜åŒ–ç‰ˆæœ¬
å®ç°é«˜æ€§èƒ½SDFè®¡ç®—å’Œæ‰«æ ä½“ç§¯åˆ†æ

æ ¸å¿ƒæŠ€æœ¯ç‰¹ç‚¹ï¼š
- Numba JITç¼–è¯‘åŠ é€Ÿæ ¸å¿ƒè®¡ç®—
- å¹¶è¡Œè®¡ç®—æ”¯æŒå¤§è§„æ¨¡SDFæŸ¥è¯¢
- Armijoçº¿æœç´¢ä¼˜åŒ–ç®—æ³•
- ç¼“å­˜æœºåˆ¶å‡å°‘é‡å¤è®¡ç®—
- å·¥ä¸šçº§æ•°å€¼ç¨³å®šæ€§ä¿è¯
"""
import numpy as np
from typing import List, Tuple, Optional, Dict, Any
import time
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
import warnings

try:
    import numba
    NUMBA_AVAILABLE = True
except ImportError:
    NUMBA_AVAILABLE = False
    warnings.warn("Numba not available, using pure Python (slower)")

from utils.math_utils import MathUtils
from utils.config import config


class SDFCalculatorOptimized:
    """
    é«˜æ€§èƒ½SDFè®¡ç®—å™¨ - å·¥ä¸šçº§ä¼˜åŒ–ç‰ˆæœ¬
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    - æœºå™¨äººå½¢çŠ¶SDFè®¡ç®—
    - æ‰«æ ä½“ç§¯SDFè®¡ç®— 
    - å¤šçº¿ç¨‹å¹¶è¡Œè®¡ç®—
    - æ™ºèƒ½ç¼“å­˜æœºåˆ¶
    - Armijoçº¿æœç´¢ä¼˜åŒ–
    """
    
    def __init__(self, robot_length: float, robot_width: float, 
                 grid_resolution: float = 0.05, enable_parallel: bool = True,
                 num_workers: int = 4, cache_size: int = 10000):
        self.robot_length = robot_length
        self.robot_width = robot_width
        self.grid_resolution = grid_resolution
        
        # å¹¶è¡Œè®¡ç®—é…ç½®
        self.enable_parallel = enable_parallel
        self.num_workers = num_workers
        self.executor = ThreadPoolExecutor(max_workers=num_workers) if enable_parallel else None
        
        # ç¼“å­˜æœºåˆ¶
        self.cache_size = cache_size
        self._sdf_cache = {}
        self._cache_lock = threading.Lock()
        self._cache_access_count = {}
        self._cache_hits = 0
        self._cache_misses = 0
        
        # æ€§èƒ½ç›‘æ§
        self.computation_times = {
            'robot_sdf': [],
            'swept_volume_sdf': [],
            'armijo_search': [],
            'parallel_computation': []
        }
        
        # ä¼˜åŒ–å‚æ•°
        self.armijo_c1 = 1e-4
        self.armijo_alpha = 0.5
        self.armijo_max_iter = 50
        self.numerical_epsilon = 1e-12
        
        print(f"âœ… SDFè®¡ç®—å™¨å·²åˆå§‹åŒ–ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰")
        print(f"   - å¹¶è¡Œè®¡ç®—: {'å¯ç”¨' if enable_parallel else 'ç¦ç”¨'}")
        print(f"   - å·¥ä½œçº¿ç¨‹: {num_workers}")
        print(f"   - ç¼“å­˜å¤§å°: {cache_size}")
        print(f"   - NumbaåŠ é€Ÿ: {'å¯ç”¨' if NUMBA_AVAILABLE else 'ç¦ç”¨'}")
    
    def compute_robot_sdf(self, query_point: np.ndarray, robot_pose: np.ndarray) -> float:
        """
        è®¡ç®—æŸ¥è¯¢ç‚¹åˆ°æœºå™¨äººçš„SDF
        
        Args:
            query_point: æŸ¥è¯¢ç‚¹ä¸–ç•Œåæ ‡ [x, y]
            robot_pose: æœºå™¨äººä½å§¿ [x, y, theta]
            
        Returns:
            SDFå€¼ï¼ˆè´Ÿå€¼è¡¨ç¤ºåœ¨æœºå™¨äººå†…éƒ¨ï¼‰
        """
        start_time = time.time()
        
        # æ£€æŸ¥ç¼“å­˜
        cache_key = self._create_cache_key(query_point, robot_pose)
        cached_result = self._get_from_cache(cache_key)
        if cached_result is not None:
            self._cache_hits += 1
            return cached_result
        
        self._cache_misses += 1
        
        # è½¬æ¢åˆ°æœºå™¨äººå±€éƒ¨åæ ‡ç³»
        point_local = MathUtils.world_to_robot_frame(query_point, robot_pose)
        
        # è®¡ç®—çŸ©å½¢SDF
        if NUMBA_AVAILABLE:
            sdf_value = self._rectangle_sdf_numba(
                point_local[0], point_local[1], 
                self.robot_length, self.robot_width)
        else:
            sdf_value = self._rectangle_sdf_python(
                point_local[0], point_local[1],
                self.robot_length, self.robot_width)
        
        # ç¼“å­˜ç»“æœ
        self._add_to_cache(cache_key, sdf_value)
        
        # è®°å½•æ€§èƒ½
        computation_time = time.time() - start_time
        self.computation_times['robot_sdf'].append(computation_time)
        
        return sdf_value
    
    def compute_swept_volume_sdf(self, query_point: np.ndarray,
                               trajectory: List[np.ndarray]) -> float:
        """
        è®¡ç®—æ‰«æ ä½“ç§¯SDF
        ä½¿ç”¨Armijoçº¿æœç´¢æ‰¾åˆ°æœ€ä¼˜æ—¶é—´t*
        
        Args:
            query_point: æŸ¥è¯¢ç‚¹ä¸–ç•Œåæ ‡ [x, y]
            trajectory: è½¨è¿¹ç‚¹åˆ—è¡¨ï¼Œæ¯ä¸ªç‚¹ä¸º [x, y, theta, time]
            
        Returns:
            æ‰«æ ä½“ç§¯SDFå€¼
        """
        start_time = time.time()
        
        if not trajectory:
            return float('inf')
        
        # ä½¿ç”¨Armijoçº¿æœç´¢æ‰¾æœ€ä¼˜æ—¶é—´
        search_start = time.time()
        optimal_time = self._armijo_line_search_optimized(query_point, trajectory)
        search_time = time.time() - search_start
        self.computation_times['armijo_search'].append(search_time)
        
        # åœ¨æœ€ä¼˜æ—¶é—´æ’å€¼æœºå™¨äººä½å§¿
        robot_pose = self._interpolate_robot_pose(trajectory, optimal_time)
        
        # è®¡ç®—SDF
        sdf_value = self.compute_robot_sdf(query_point, robot_pose)
        
        # è®°å½•æ€§èƒ½
        computation_time = time.time() - start_time
        self.computation_times['swept_volume_sdf'].append(computation_time)
        
        return sdf_value
    
    def compute_swept_volume_parallel(self, query_points: np.ndarray,
                                    trajectory: List[np.ndarray]) -> np.ndarray:
        """
        å¹¶è¡Œè®¡ç®—å¤šä¸ªæŸ¥è¯¢ç‚¹çš„æ‰«æ ä½“ç§¯SDF
        
        Args:
            query_points: æŸ¥è¯¢ç‚¹æ•°ç»„ [N, 2]
            trajectory: è½¨è¿¹ç‚¹åˆ—è¡¨
            
        Returns:
            SDFå€¼æ•°ç»„ [N]
        """
        start_time = time.time()
        
        if not self.enable_parallel or self.executor is None:
            # ä¸²è¡Œè®¡ç®—
            sdf_values = np.array([
                self.compute_swept_volume_sdf(point, trajectory) 
                for point in query_points
            ])
        else:
            # å¹¶è¡Œè®¡ç®—
            chunk_size = max(1, len(query_points) // self.num_workers)
            chunks = [query_points[i:i+chunk_size] 
                     for i in range(0, len(query_points), chunk_size)]
            
            futures = []
            for chunk in chunks:
                future = self.executor.submit(self._compute_chunk_sdf, chunk, trajectory)
                futures.append(future)
            
            sdf_values = []
            for future in as_completed(futures):
                chunk_results = future.result()
                sdf_values.extend(chunk_results)
            
            sdf_values = np.array(sdf_values)
        
        # è®°å½•æ€§èƒ½
        computation_time = time.time() - start_time
        self.computation_times['parallel_computation'].append(computation_time)
        
        return sdf_values
    
    def compute_obstacle_cost(self, trajectory: List[np.ndarray],
                            obstacles: List[Dict]) -> float:
        """
        è®¡ç®—è½¨è¿¹çš„éšœç¢ç‰©ä»£ä»·
        
        Args:
            trajectory: è½¨è¿¹ç‚¹åˆ—è¡¨
            obstacles: éšœç¢ç‰©åˆ—è¡¨
            
        Returns:
            éšœç¢ç‰©ä»£ä»·å€¼
        """
        if not obstacles or not trajectory:
            return 0.0
        
        total_cost = 0.0
        safety_margin = 0.2  # å®‰å…¨è¾¹è·
        
        for traj_point in trajectory:
            robot_pose = traj_point[:3]
            
            for obstacle in obstacles:
                # è®¡ç®—æœºå™¨äººä¸éšœç¢ç‰©çš„æœ€å°è·ç¦»
                min_distance = self._compute_robot_obstacle_distance(robot_pose, obstacle)
                
                # å¦‚æœè·ç¦»å°äºå®‰å…¨è¾¹è·ï¼Œè®¡ç®—ä»£ä»·
                if min_distance < safety_margin:
                    # ä½¿ç”¨æŒ‡æ•°å‡½æ•°è®¡ç®—ä»£ä»·ï¼ˆè·ç¦»è¶Šè¿‘ä»£ä»·è¶Šé«˜ï¼‰
                    cost = np.exp(-min_distance / 0.1)
                    total_cost += cost
        
        return total_cost
    
    def build_environment_sdf_grid(self, obstacles: List[Dict],
                                  bounds: np.ndarray,
                                  resolution: float = None) -> np.ndarray:
        """
        æ„å»ºç¯å¢ƒSDFç½‘æ ¼
        
        Args:
            obstacles: éšœç¢ç‰©åˆ—è¡¨
            bounds: è¾¹ç•Œ [x_min, y_min, x_max, y_max]
            resolution: ç½‘æ ¼åˆ†è¾¨ç‡
            
        Returns:
            SDFç½‘æ ¼
        """
        if resolution is None:
            resolution = self.grid_resolution
        
        x_min, y_min, x_max, y_max = bounds
        grid_width = int((x_max - x_min) / resolution) + 1
        grid_height = int((y_max - y_min) / resolution) + 1
        
        # åˆ›å»ºæŸ¥è¯¢ç‚¹ç½‘æ ¼
        query_points = []
        for i in range(grid_height):
            for j in range(grid_width):
                x = x_min + j * resolution
                y = y_min + i * resolution
                query_points.append([x, y])
        
        query_points = np.array(query_points)
        
        # å¹¶è¡Œè®¡ç®—SDFå€¼
        if self.enable_parallel:
            sdf_values = self._compute_environment_sdf_parallel(query_points, obstacles)
        else:
            sdf_values = self._compute_environment_sdf_serial(query_points, obstacles)
        
        # é‡å¡‘ä¸ºç½‘æ ¼
        sdf_grid = sdf_values.reshape(grid_height, grid_width)
        
        return sdf_grid
    
    # === å†…éƒ¨ä¼˜åŒ–æ–¹æ³• ===
    
    def _compute_chunk_sdf(self, chunk_points: np.ndarray, 
                          trajectory: List[np.ndarray]) -> List[float]:
        """è®¡ç®—ç‚¹å—çš„SDFå€¼"""
        return [self.compute_swept_volume_sdf(point, trajectory) 
                for point in chunk_points]
    
    def _armijo_line_search_optimized(self, query_point: np.ndarray,
                                    trajectory: List[np.ndarray]) -> float:
        """
        ä¼˜åŒ–çš„Armijoçº¿æœç´¢ç®—æ³•
        ä½¿ç”¨é‡‘åˆ†æœç´¢å’ŒäºŒåˆ†æœç´¢æ··åˆç­–ç•¥
        """
        if len(trajectory) < 2:
            return trajectory[0][3]
        
        t_min = trajectory[0][3]
        t_max = trajectory[-1][3]
        
        # ä½¿ç”¨ä¸‰ç‚¹æœç´¢æ‰¾åˆ°ç²—ç•¥æœ€ä¼˜åŒºé—´
        t1 = t_min + (t_max - t_min) * 0.382  # é»„é‡‘åˆ†å‰²ç‚¹
        t2 = t_min + (t_max - t_min) * 0.618
        
        f1 = self._evaluate_sdf_at_time(query_point, trajectory, t1)
        f2 = self._evaluate_sdf_at_time(query_point, trajectory, t2)
        
        # ä½¿ç”¨é»„é‡‘åˆ†å‰²æœç´¢ç²¾ç¡®åŒ–
        tolerance = (t_max - t_min) * 1e-6
        
        for _ in range(self.armijo_max_iter):
            if abs(t_max - t_min) < tolerance:
                break
            
            if f1 < f2:
                t_max = t2
                t2 = t1
                f2 = f1
                t1 = t_min + (t_max - t_min) * 0.382
                f1 = self._evaluate_sdf_at_time(query_point, trajectory, t1)
            else:
                t_min = t1
                t1 = t2
                f1 = f2
                t2 = t_min + (t_max - t_min) * 0.618
                f2 = self._evaluate_sdf_at_time(query_point, trajectory, t2)
        
        return (t_min + t_max) / 2.0
    
    def _evaluate_sdf_at_time(self, query_point: np.ndarray, 
                             trajectory: List[np.ndarray], time: float) -> float:
        """åœ¨æŒ‡å®šæ—¶é—´è¯„ä¼°SDFå€¼"""
        robot_pose = self._interpolate_robot_pose(trajectory, time)
        return self.compute_robot_sdf(query_point, robot_pose)
    
    def _interpolate_robot_pose(self, trajectory: List[np.ndarray], time: float) -> np.ndarray:
        """è½¨è¿¹æ’å€¼è·å–æœºå™¨äººä½å§¿"""
        if not trajectory:
            return np.array([0, 0, 0])
        
        if time <= trajectory[0][3]:
            return trajectory[0][:3]
        
        if time >= trajectory[-1][3]:
            return trajectory[-1][:3]
        
        # æ‰¾åˆ°æ—¶é—´åŒºé—´
        for i in range(len(trajectory) - 1):
            if trajectory[i][3] <= time <= trajectory[i+1][3]:
                t1, t2 = trajectory[i][3], trajectory[i+1][3]
                
                if abs(t2 - t1) < self.numerical_epsilon:
                    return trajectory[i][:3]
                
                # çº¿æ€§æ’å€¼
                alpha = (time - t1) / (t2 - t1)
                pose = (1 - alpha) * trajectory[i][:3] + alpha * trajectory[i+1][:3]
                
                # è§’åº¦æ’å€¼éœ€è¦ç‰¹æ®Šå¤„ç†
                pose[2] = MathUtils.interpolate_angle(trajectory[i][2], trajectory[i+1][2], alpha)
                
                return pose
        
        return trajectory[-1][:3]
    
    def _compute_robot_obstacle_distance(self, robot_pose: np.ndarray, 
                                       obstacle: Dict) -> float:
        """è®¡ç®—æœºå™¨äººä¸éšœç¢ç‰©çš„æœ€å°è·ç¦»"""
        # ç®€åŒ–å®ç°ï¼šå‡è®¾éšœç¢ç‰©ä¸ºåœ†å½¢
        obstacle_center = np.array([obstacle.get('x', 0), obstacle.get('y', 0)])
        obstacle_radius = obstacle.get('radius', 0.5)
        
        robot_center = robot_pose[:2]
        distance_to_center = np.linalg.norm(robot_center - obstacle_center)
        
        # æœºå™¨äººçš„å¤–æ¥åœ†åŠå¾„
        robot_radius = np.sqrt(self.robot_length**2 + self.robot_width**2) / 2.0
        
        # æœ€å°è·ç¦» = ä¸­å¿ƒè·ç¦» - ä¸¤ä¸ªåŠå¾„
        min_distance = max(0, distance_to_center - obstacle_radius - robot_radius)
        
        return min_distance
    
    def _compute_environment_sdf_parallel(self, query_points: np.ndarray,
                                        obstacles: List[Dict]) -> np.ndarray:
        """å¹¶è¡Œè®¡ç®—ç¯å¢ƒSDF"""
        chunk_size = max(1, len(query_points) // self.num_workers)
        chunks = [query_points[i:i+chunk_size] 
                 for i in range(0, len(query_points), chunk_size)]
        
        futures = []
        for chunk in chunks:
            future = self.executor.submit(self._compute_environment_sdf_chunk, chunk, obstacles)
            futures.append(future)
        
        sdf_values = []
        for future in as_completed(futures):
            chunk_results = future.result()
            sdf_values.extend(chunk_results)
        
        return np.array(sdf_values)
    
    def _compute_environment_sdf_chunk(self, chunk_points: np.ndarray,
                                     obstacles: List[Dict]) -> List[float]:
        """è®¡ç®—ç‚¹å—çš„ç¯å¢ƒSDF"""
        sdf_values = []
        
        for point in chunk_points:
            min_distance = float('inf')
            
            for obstacle in obstacles:
                distance = self._point_to_obstacle_distance(point, obstacle)
                min_distance = min(min_distance, distance)
            
            sdf_values.append(min_distance)
        
        return sdf_values
    
    def _compute_environment_sdf_serial(self, query_points: np.ndarray,
                                      obstacles: List[Dict]) -> np.ndarray:
        """ä¸²è¡Œè®¡ç®—ç¯å¢ƒSDF"""
        return np.array([
            min(self._point_to_obstacle_distance(point, obstacle) 
                for obstacle in obstacles) if obstacles else float('inf')
            for point in query_points
        ])
    
    def _point_to_obstacle_distance(self, point: np.ndarray, obstacle: Dict) -> float:
        """è®¡ç®—ç‚¹åˆ°éšœç¢ç‰©çš„è·ç¦»"""
        obstacle_center = np.array([obstacle.get('x', 0), obstacle.get('y', 0)])
        obstacle_radius = obstacle.get('radius', 0.5)
        
        distance_to_center = np.linalg.norm(point - obstacle_center)
        return max(0, distance_to_center - obstacle_radius)
    
    # === ç¼“å­˜ç®¡ç† ===
    
    def _create_cache_key(self, query_point: np.ndarray, robot_pose: np.ndarray) -> str:
        """åˆ›å»ºç¼“å­˜é”®"""
        # å¯¹åæ ‡è¿›è¡Œé‡åŒ–ä»¥æé«˜ç¼“å­˜å‘½ä¸­ç‡
        qx = round(query_point[0] / self.grid_resolution) * self.grid_resolution
        qy = round(query_point[1] / self.grid_resolution) * self.grid_resolution
        rx = round(robot_pose[0] / self.grid_resolution) * self.grid_resolution
        ry = round(robot_pose[1] / self.grid_resolution) * self.grid_resolution
        rtheta = round(robot_pose[2] / 0.1) * 0.1  # è§’åº¦é‡åŒ–åˆ°0.1å¼§åº¦
        
        return f"{qx:.3f},{qy:.3f},{rx:.3f},{ry:.3f},{rtheta:.3f}"
    
    def _get_from_cache(self, key: str) -> Optional[float]:
        """ä»ç¼“å­˜è·å–å€¼"""
        with self._cache_lock:
            if key in self._sdf_cache:
                # æ›´æ–°è®¿é—®è®¡æ•°
                self._cache_access_count[key] = self._cache_access_count.get(key, 0) + 1
                return self._sdf_cache[key]
            return None
    
    def _add_to_cache(self, key: str, value: float):
        """æ·»åŠ å€¼åˆ°ç¼“å­˜"""
        with self._cache_lock:
            if len(self._sdf_cache) >= self.cache_size:
                # ä½¿ç”¨LFUç­–ç•¥æ¸…ç†ç¼“å­˜
                self._cleanup_cache()
            
            self._sdf_cache[key] = value
            self._cache_access_count[key] = 1
    
    def _cleanup_cache(self):
        """æ¸…ç†ç¼“å­˜ï¼ˆLFUç­–ç•¥ï¼‰"""
        if not self._cache_access_count:
            return
        
        # ç§»é™¤æœ€å°‘ä½¿ç”¨çš„25%æ¡ç›®
        sorted_items = sorted(self._cache_access_count.items(), key=lambda x: x[1])
        remove_count = len(sorted_items) // 4
        
        for key, _ in sorted_items[:remove_count]:
            self._sdf_cache.pop(key, None)
            self._cache_access_count.pop(key, None)
    
    # === Numbaä¼˜åŒ–å‡½æ•° ===
    
    if NUMBA_AVAILABLE:
        @staticmethod
        @numba.jit(nopython=True, cache=True)
        def _rectangle_sdf_numba(point_local_x: float, point_local_y: float,
                               length: float, width: float) -> float:
            """
            ä½¿ç”¨Numbaä¼˜åŒ–çš„çŸ©å½¢SDFè®¡ç®—
            å®ç°è®ºæ–‡Equation (7)
            """
            dx = abs(point_local_x) - length / 2.0
            dy = abs(point_local_y) - width / 2.0
            
            if dx > 0.0 and dy > 0.0:
                # å¤–éƒ¨è§’ç‚¹ï¼šæ¬§å‡ é‡Œå¾—è·ç¦»
                return np.sqrt(dx * dx + dy * dy)
            else:
                # è¾¹ç•Œæˆ–å†…éƒ¨ï¼šåˆ‡æ¯”é›ªå¤«è·ç¦»
                return max(dx, dy)
    
    @staticmethod
    def _rectangle_sdf_python(point_local_x: float, point_local_y: float,
                            length: float, width: float) -> float:
        """
        çº¯PythonçŸ©å½¢SDFè®¡ç®—ï¼ˆNumbaä¸å¯ç”¨æ—¶çš„åå¤‡ï¼‰
        """
        dx = abs(point_local_x) - length / 2.0
        dy = abs(point_local_y) - width / 2.0
        
        if dx > 0.0 and dy > 0.0:
            # å¤–éƒ¨è§’ç‚¹ï¼šæ¬§å‡ é‡Œå¾—è·ç¦»
            return np.sqrt(dx * dx + dy * dy)
        else:
            # è¾¹ç•Œæˆ–å†…éƒ¨ï¼šåˆ‡æ¯”é›ªå¤«è·ç¦»
            return max(dx, dy)
    
    # === æ€§èƒ½åˆ†æ ===
    
    def get_performance_metrics(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æŒ‡æ ‡"""
        metrics = {}
        
        for operation, times in self.computation_times.items():
            if times:
                metrics[operation] = {
                    'count': len(times),
                    'total_time': sum(times),
                    'avg_time': np.mean(times),
                    'min_time': min(times),
                    'max_time': max(times),
                    'std_time': np.std(times)
                }
            else:
                metrics[operation] = {
                    'count': 0,
                    'total_time': 0,
                    'avg_time': 0,
                    'min_time': 0,
                    'max_time': 0,
                    'std_time': 0
                }
        
        # ç¼“å­˜ç»Ÿè®¡
        total_requests = self._cache_hits + self._cache_misses
        metrics['cache'] = {
            'hits': self._cache_hits,
            'misses': self._cache_misses,
            'hit_rate': self._cache_hits / total_requests if total_requests > 0 else 0,
            'cache_size': len(self._sdf_cache),
            'max_cache_size': self.cache_size
        }
        
        return metrics
    
    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        with self._cache_lock:
            self._sdf_cache.clear()
            self._cache_access_count.clear()
            self._cache_hits = 0
            self._cache_misses = 0
    
    def reset_performance_counters(self):
        """é‡ç½®æ€§èƒ½è®¡æ•°å™¨"""
        for key in self.computation_times:
            self.computation_times[key] = []
        self._cache_hits = 0
        self._cache_misses = 0
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.executor:
            self.executor.shutdown(wait=True)
        self.clear_cache()
        print("ğŸ§¹ SDFè®¡ç®—å™¨èµ„æºæ¸…ç†å®Œæˆ")


# å·¥å‚å‡½æ•°
def create_sdf_calculator(robot_length: float, robot_width: float,
                         enable_optimization: bool = True) -> SDFCalculatorOptimized:
    """åˆ›å»ºä¼˜åŒ–çš„SDFè®¡ç®—å™¨"""
    return SDFCalculatorOptimized(
        robot_length=robot_length,
        robot_width=robot_width,
        enable_parallel=enable_optimization,
        num_workers=4 if enable_optimization else 1,
        cache_size=10000 if enable_optimization else 100
    )
